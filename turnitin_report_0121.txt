您的遞交已成功上載至Turnitin

電子回條
Turnitin 遞交ID: 1491350971

提取提交:

國立交通大學 應用數學系 碩士論文 有向圖譜半徑之簡易比較方法 A simple method on comparison between spectral radii of two directed graphs 研究生：陳科翰 指導教授：翁志文教授中華民國一百ㄧ十年一月有向圖譜半徑之簡易比較方法 A simple method on comparison between spectral radii of two directed graphs Student: Ko-Han Chen 研究生:陳科翰 Advisor: Chih-Wen Weng 指導教授：翁志文教授 國立交通大學 應用數學系 碩士論文 A Thesis Submitted to Department of Applied Mathematics College of Science National Chiao Tung University in Partial Fulfillment of Requirements for the Degree of Master in Applied Mathematics January 2021 Hsinchu, Taiwan, Republic of China 中華民國一百ㄧ十年一月 有向圖譜半徑之簡易比較方法研究生：陳科翰 指導教授：翁志文教授國立交通大學 應用數學系 摘要 矩陣的譜半徑為其特徵值絕對值的最大值，而一有向圖的譜半徑則定義為其鄰接矩陣之譜半徑。本論文給出一個比較方陣譜半徑的方法，將此方法應用於有向圖的鄰接矩陣，我們可以簡易比較有向圖的譜半徑。 關鍵詞：譜半徑、鄰接矩陣 i A simple method on comparison between spectral radii of two directed graphs Student: Ko-Han Chen Advisor: Chih-Wen Weng Department of Applied Mathematics National Chiao Tung University Abstract The spectral radius of a square matrix is the largest magnitude of its eigenvalues. And the spectral radius of a directed graph is defined as the spectral radius of the corresponding adjacency matrix. In this paper, we give an approach to compare the spectral radii of two nonnegative matrices. By applying this method on the adjacency matrix of a directed graph, we can compare the spectral radii of two directed graphs simply. Keywords: spectral radius, adjacency matrix ii Contents Abstract (in Chinese) Abstract (in English) i ii 1 Introduction 1 2 Preliminaries 2 3 Our Method 4 Bibliography 11 iii 1 Introduction Let R and C denote the field of real numbers and complex numbers, respec- tively. Let C be an n × n real square matrix. If there is a nonzero column vector u ∈ C n such that Cu = λu for some scalar λ ∈ C, then the scalar λ is called the eigenvalue of C with corresponding eigenvector u. And the spectral radius of a matrix C is the largest magnitude (or complex modu- lus) of its eigenvalues, denoted by ρ(C). We are interested in the spectral radius of the following matrix associated with a simple directed graph. Definition 1.1. Given a directed graph G, the adjacency matrix of G is the square matrix A = (a ij ) indexed by vertices of G, and ⎧ ⎪⎨ 1, if ji is an arc in G, a ij = ⎪⎩ 0, otherwise. Given a directed graph G, the spectral radius of G is the spectral radius of the adjacency matrix of G, denoted by ρ(G). Note that the spectral radius ρ(G) is independent of the ordering of the vertex set of G. Conversely, we can also define a directed graph G from a given nonneg- ative n × n matrix C = (c ij ) by setting the vertex set {1, 2, . . . , n} and edge set {ij : c ij > 0}. The matrix C is irreducible if the defined graph G from C is strongly connected. The spectral radius is an important indicator to specify the relation of connected vertices in a graph, so it is meaningful to find a simple method to estimate the spectral radius. A simple and excellent executable method to estimate the spectral radius has some features, first, the bios is minimized, and second, there must be a way to prove it sensible. Enumerate these factors and prove it correctly would make this method reliable. In [1], Cheng and Weng give many bounds of the spectral radius of 1 a nonnegative square matrix. And based on their theory and Perron- Frobenius theorem, we give another approach to obtain an upper bound of the spectral radius and apply it on the adjacency matrix of a directed graph. All theorems come from continuous discussions between C.W. Weng and K.H. Chen. These were all documented.[5] 2 Preliminaries The following is Perron–Frobenius theorem, which provides a feature of nonnegative eigenvectors to nonnegative matrices. Theorem 2.1. [3] If C is a nonnegative square matrix, then the spectral radius ρ(C) is an eigenvalue of C with a corresponding nonnegative right eigenvector and a corresponding nonnegative left eigenvector. Moreover if C is irreducible the above eigenvectors can be chosen to be positive. A well-known application of Theorem 2.1 show that if matrix C ′ majors C (in notation C ≤ C ′ ), i.e. c ij ≤ c ′ ij for all ij, j, then ρ(C) ≤ ρ(C′ ). Our main result shows that the assumption C ≤ C ′ can be a little loosen. Our theory is based on the following theorem, which is from [1]. Theorem 2.2. Let C = (c ij ), C ′ = (c ′ ij ) be n × n real matrices with real eigenvalues λ, λ ′ respectively such that there exist n × n matrices P and Q satisfying the following (i)-(iv). (i)PCQ≤ P C′Q; (ii) an eigenvector Qu of C ′ associated with eigenvalue λ ′ exists for some nonnegative column vector u = (u 1 , u2, ... , u n ) T. 2 (iii)a left eigenvector v T P of C ′ associated with eigenvalue λ exists for somenonnegative row vector v T = (v 1 , v2, ... , v n ); and (iv)v TPQu>0. Then λ ≤ λ ′ . Moreover, λ = λ ′ if and only if (P C′ Q) ij= (P CQ) ij for 1 ≤ i, j ≤ n with v i ≠ 0and u j ≠ 0. (1) Proof. Multiplying the nonnegative vector u in assumption (i) to the right of both terms of (i), P CQu≤P C ′ Qu = λ ′ P Qu,(2) where the above eq