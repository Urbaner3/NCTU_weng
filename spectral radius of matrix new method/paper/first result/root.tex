\documentclass{article}

%\usetheme{Warsaw}
\usepackage{times}  % fonts are up to you
\usepackage{amssymb, amsmath, mathrsfs,amsthm}
\usepackage{multicol}
\usepackage{bm}
\usepackage{ulem}


\usepackage{fontspec}
\usepackage{xeCJK}
%\setCJKmainfont{微軟正黑體}
\setCJKmainfont{simsun.ttf}
\setCJKsansfont{simhei.ttf}
\setCJKmonofont{simfang.ttf}
\XeTeXlinebreaklocale "zh"
\XeTeXlinebreakskip = 0pt plus 1pt

\begin{document}

% THEOREMS ---------------------------------------------------------------
\theoremstyle{plain}
% block中的字會變成數學體, 斜體字
\newtheorem{thm}{Theorem}[section]
\newtheorem{cor}[thm]{Corollary}
\newtheorem{lem}[thm]{Lemma}
\newtheorem{prop}[thm]{Proposition}
\newtheorem{remark}[thm]{Remark}
\newtheorem{pf}[thm]{Proof}

\newtheorem{eg}[thm]{Example}
\newtheorem{conj}[thm]{Conjecture}

\theoremstyle{definition}
% block中的字是正常字體
\newtheorem{ex}[thm]{Exercise}
\newtheorem{defn}[thm]{Definition}
\newtheorem{prob}[thm]{Problem}
\newtheorem{exam}[thm]{Example}
\newtheorem{rem}[thm]{Remark}

\newtheorem{algo}[thm]{Algorithm}

\section{Our first result}

\begin{thm} \label{thm_main}
    Let $C=(c_{ij})$, $C'=(c'_{ij})$ be  $n\times n$ matrices.
Assume that
\begin{enumerate}
\item[(i)]   $C[-|n)\leq C'[-|n)$ and $c_{ik}+c_{in}\leq c'_{ik}+c'_{in}$ for all $1\leq i\leq n$;
\item[(ii)] there exist a $k$-rooted vector $v'=(v'_1, v'_2, \ldots, v'_n)^T$ and a scalar $\lambda'\in \mathbb{R}$
such that $\lambda'$ is an eigenvalue of $C'$ with associated eigenvector $v'$;
\item[(iii)] there exists a nonnegative vector $v^T=(v_1, v_2, \ldots, v_n)$ and a scalar $\lambda\in \mathbb{R}$ such that $\lambda$ is an eigenvalue of $C$ with associated left eigenvector $v^T$;
\item[(iv)] $v^Tv'>0.$
\end{enumerate}
 Then $\lambda\leq \lambda'$.
Moreover, $\lambda=\lambda'$
if and only if
\begin{enumerate}
\item[(a)] $c_{ik}+c_{in}=c'_{ik}+c'_{in}$\qquad for $1\leq i\leq n$ with $v_i\not=0$ and $v'_n\not=0;$
\item[(b)]
$c'_{ij}=c_{ij}\qquad \hbox{for~}1\leq i\leq n,~1\leq j\leq n-1 \hbox{~with~} v_i\ne 0 \hbox{~and~} v'_j> v'_n.$
\end{enumerate} \qed
\end{thm}




{\bf $k$-rooted matrix}

\begin{defn}[(k,n)-sum]
For a matrix $C'=(c'_{ij})$ of $n$ columns, the $(k, n)$-{\it sum} vector of $C'$ is the vector of the sum of the $k$-th and  $n$-th columns of $C'$, where $k\leq n-1$.
\end{defn}

\begin{defn}[k-rooted matrix]
A  matrix $C'=(c'_{ij})$ is called {\it $k$-rooted}  if its  columns and its $(k, n)$-sum vector are all $k$-rooted except the last column of $C'$.
\end{defn}

\begin{thm}
Let $C'=(c'_{ij})$ be an $n\times n$ nonnegative matrix. Then the following (i)-(iii) hold.
    \begin{enumerate}
        \item[(i)]$C'$ is a $k$-rooted matrix, if and only if, $Q^{-1}C'Q$ is nonnegative.
        \item[(ii)]$C'$ has a $k$-rooted eigenvector $v'=Qu$ for $\rho(C')$ as an eigenvalue. $u$ is a nonnegative eigenvector of $Q^{-1}C'Q$ for $\rho(C')$.
        \item[(iii)] $\rho(C')$ = $\rho(Q^{-1}C'Q)$
    \end{enumerate}


\begin{pf}
\subsection{}
is immediate from Definition~\ref{d_rooted} and the observation that 
$$Q^{-1}=I-E_{kn}=\begin{pmatrix}
1 &  & & &  & 0 \\
 & 1 &  &      &  &  \\
 &  & \ddots & &  & -1 \\
 &  &        & &  &  \\
  &  & & & 1 &  \\
0 &  & & &  & 1 \\
\end{pmatrix},$$
and $Q^{-1}C'Q$ is 
$$\begin{pmatrix}
c'_{11}     & c'_{12} & \cdots     & c'_{1\ n-1} & c'_{1k}+c'_{1n} \\
\vdots \\
c'_{k-11}     & c'_{k-1 2}           & \cdots     & c'_{k-1 n-1} & c'_{k-1k}+c'_{k-1n} \\
c'_{k1}-c'_{n1} & c'_{k2}-c'_{n2} &\cdots      &c'_{kn-1}-c'_{nk-1}& c'_{kk}+c'_{kn}-c'_{nk}-x'_{nn}\\
c'_{k+11}     & c'_{k+12}           & \cdots     & c'_{k+1\ n-1} & c'_{k+1k}+c'_{k+1n} \\
\vdots              & \vdots & \ddots              & \vdots & \vdots \\
c'_{n1}             & c'_{n2} & \cdots             & c'_{n\ n-1} & c'_{nk}+c'_{nn} \\
\end{pmatrix}.
$$




\subsection{(ii)}

By Lemma~\ref{l1.4} $v'=Qu$ is $k$-rooted. 
Since $Q^{-1}C'Qu=\rho(C')u$ by the assumption, we have 
$C'Qu=\rho(C')Qu$.



\subsection{(iii)}

Since $C'$ and $Q^{-1}C'Q$ have the same set of eigenvalues, clearly $\rho(C')$ = $\rho(Q^{-1}C'Q)$.

\end{pf}
\end{thm}


\begin{lem}\label{l_diag}
If a square matrix $C'$ has a rooted eigenvector for $\lambda'$, then $C'+dI$ also has
the same rooted eigenvector for $\lambda'+d,$ where $d$ is a constant and $I$ is the identity matrix with the same size of $C'$.
\end{lem}




\end{document}
