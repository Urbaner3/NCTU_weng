\documentclass[12pt]{report}

\topmargin 0pt

\topmargin=-1.5cm
\oddsidemargin=0.7cm
\textheight=23.5cm
\textwidth=15cm
\setlength{\baselineskip}{24pt}
\renewcommand{\baselinestretch}{1.5} %行距




\usepackage{fontspec}   %加這個就可以設定字體
\usepackage{xeCJK}       %讓中英文字體分開設置
%\usepackage{times}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{ulem}
\usepackage{amsfonts}
\usepackage{mathrsfs}
\usepackage{tabularx,array}
\usepackage{pgf,tikz}
\usepackage{blkarray} %line 80-92 Q formula matrix index
%\usepackage{colortbl}
\usepackage{enumitem}% enumerate labels   roman

\usetikzlibrary{arrows}
\setCJKmainfont{標楷體} %設定中文為系統上的字型，而英文不去更動，使用原TeX字型
\XeTeXlinebreaklocale "zh"             %這兩行一定要加，中文才能自動換行
\XeTeXlinebreakskip = 0pt plus1pt     %這兩行一定要加，中文才能自動換行
\title{Combinatorial Identities from Lagrange's Interpolation Polynomial}
\author{Student: Yen-Jung Huang  ~~~~~~~~~~~~~~~~~~~~~~~~~~Advisor: Chih-Wen Weng}
\date{} %不要日期

\def\UrlFont{\rm}


\theoremstyle{plain}
\newtheorem{thm}{Theorem}[chapter]
\newtheorem{cor}[thm]{Corollary}
\newtheorem{lem}[thm]{Lemma}
\newtheorem{prop}[thm]{Proposition}
\newtheorem{remark}[thm]{Remark}
\newtheorem{eg}[thm]{Example}
\newtheorem{conj}[thm]{Conjecture}


\theoremstyle{definition}
\newtheorem{defn}[thm]{Definition}
\newtheorem{ex}[thm]{Exercise}
\newtheorem{prob}[thm]{Problem}
\newtheorem{exam}[thm]{Example}
\newtheorem{nota}[thm]{Notation}
\newtheorem{rem}[thm]{Remark}
\newtheorem{ques}[thm]{Question}
\newtheorem{pof}[thm]{Proof.}

\usepackage{comment}

%\renewcommand {\refname} {Bibliography}



\begin{document}

\chapter{Our result}
We will prove the main Theorems introduced in the introduction. First, we need some natations.
 Throughout fix $k \in [n-1] := \{1,2,...,n-1\}$. Let $E_{kn}$ denote the $n\times n$ binary matrix with an unique $1$ appearing in the  position $(k,n)$. We will apply the Theorem 1.7 with $P=I$ and 



\begin{equation}
  \label{Q_1}
Q=I+E_{kn}=\begin{blockarray}{cccccc}
%a & b & c & d & e \\
 &  &  & &  \\
\begin{block}{(ccccc)c}
	
  1 &   &   &   &   &  \\
    & 1 &   &   &   &  \\
    &   & \ddots &   & 1 & k \\
    &   &   & 1 &   &  \\
  0 &   &   &   & 1 &  \\
\end{block}
\end{blockarray}
\end{equation}


\begin{defn}[$k$-rooted vector]%\label{k_rooted}
 A column vector $v'=(v'_1,v'_2,\ldots,v'_n)^T$ is called {\it $k$-rooted}  if $v'_{j} \geq 0$ for $1 \leq  j \leq n$ and $v'_k\geq v'_n.$
\end{defn}
\bigskip

The following Lemma is immediate from the above definition.
\bigskip

\begin{lem}\label{lem:rt_vec}
If $u=(u_1, u_2, \ldots, u_n)^T$ and $v'=(v'_1, v'_2, \ldots, v'_n):=Qu=(u_1,\ldots, u_{k-1},u_k+u_n, u_{k+1}, \ldots,  u_n)^T$, then
\begin{enumerate}[label=(\Roman*)]
\item \label{lem:rt_vec:en1}$v'$ is $k$-rooted  if and only if  $u$ is nonnegative;
\item $u_k>0$ if and only if $v'_k>v'_n$.
\end{enumerate}
\qed
\end{lem}

\begin{thm} \label{thm_main}
    Let $C=(c_{ij})$, $C'=(c'_{ij})$ be  $n\times n$ matrices.
Assume that
\begin{enumerate}[label=(\Roman*)]
\item \label{thm_main:condition_i} $C[[n]|[n-1]]\leq C'[[n]|[n-1]]$ and $c_{ik}+c_{in}\leq c'_{ik}+c'_{in}$ for all $1\leq i\leq n$;
\item \label{thm_main:condition_ii}there exists a $k$-rooted vector $v'=(v'_1, v'_2, \ldots, v'_n)^T$ and a scalar $\lambda'\in \mathbb{R}$
such that $\lambda'$ is an eigenvalue of $C'$ with associated eigenvector $v'$;
\item there exists a nonnegative vector $v^T=(v_1, v_2, \ldots, v_n)$ and a scalar $\lambda\in \mathbb{R}$ such that $\lambda$ is an eigenvalue of $C$ with associated left eigenvector $v^T$;
\item $v^Tv'>0.$
\end{enumerate}
 Then $\lambda\leq \lambda'$.
Moreover, $\lambda=\lambda'$
if and only if
\begin{enumerate}[label=(\alph*)]
\item  \label{thm_main:equ_cond_a} $c_{ik}+c_{in}=c'_{ik}+c'_{in} \qquad$  for $1\leq i\leq n$ with $v_i\not=0$ and $v'_n\not=0;$
\item \label{thm_main:equ_cond_b} $c'_{ij}=c_{ij}\qquad $for $1\leq i\leq n,~1\leq j\leq n-1, j \neq k $with $v_i\ne 0 $;
\item \label{thm_main:equ_cond_c} $c'_{ik}=c_{ik} \qquad $  for $1\leq i \leq n$ and $ v'_{k}>v'_n$ 
\end{enumerate} \qed
\end{thm}

\begin{pof}
The proof is based on Theorem~\ref{pre_thm} with $P = I$ and $Q = I + E_{kn}$ in (\ref{Q_1} ). 
The assumption \ref{pre_thm_em1} $PCQ\leq PC'Q$ of Theorem~\ref{pre_thm} holds by the condition \ref{thm_main:condition_i} of this theorem. 
Let $u = Q^{-1}v'$. Then u is nonnegative and $C'Qu = \lambda' Qu$ by the condition \ref{thm_main:condition_ii} and
 Lemma~\ref{lem:rt_vec}\ref{lem:rt_vec:en1}. Hence the assumption \ref{pre_thm_em2} of Theorem~\ref{pre_thm} holds. The assumptions \ref{pre_thm_em3} and \ref{pre_thm_em4}
  of Theorem~\ref{pre_thm} clearly hold by conditions~\ref{thm_main:condition_iii},\ref{thm_main:condition_iv} of this theorem since $P = I$ and
   $v'= Qu$  Hence $\lambda \leq \lambda' $ by the necessary condition of Theorem~\ref{pre_thm}. Moreover
    $\lambda = \lambda'$ if and only if \ref{pre0} holds, and this is equivalent to
     conditions \ref{thm_main:equ_cond_a},\ref{thm_main:equ_cond_b},\ref{thm_main:equ_cond_c} of this theorem. 
\end{pof}

We are interested in the matrices $C'$ that have $k$-rooted eigenvectors.
Motivated by the condition (i) of theorem 2.3, we provide the following two definitions. 

\begin{defn}[(k,n)-sum]
For an $n \times n$ matrix $C'=(c'_{ij})$, the $(k, n)-sum$ vector of $C'$ is the vector of the sum of the $k$-th and  $n$-th columns of $C'$.
\end{defn}

Note that the last column of $C'Q$ is the $(k, n)-sum$ vector of $C'$

\begin{defn}\label{m_rooted}
A  matrix $C'=(c'_{ij})$ is called $k-rooted$  if its  columns and its $(k, n)-sum$ vector are all $k$-rooted except the last column of $C'$.
\end{defn}

The following theorem shows that a $k$-rooted matrix has a $k$-rooted eigenvector. 

\begin{lem} \label{lma_m_rooted}
Let $C'=(c'_{ij})$ be an $n\times n$ nonnegative matrix. Then the following (i)-(iii) hold.
    \begin{enumerate}[label=(\Roman*)]
        \item $C'$ is a $k$-rooted matrix, if and only if, $Q^{-1}C'Q$ is nonnegative.
        \item Assume that $C'$ is $k$-rooted and let $u$ be a nonnegative eigenvector of $Q^{-1}C'Q$
         for $\rho(C')$. Then  $C'$ has a $k$-rooted eigenvector $v'=Qu$ for $\rho(C')$. 
        \item $\rho(C')$ = $\rho(Q^{-1}C'Q)$
    \end{enumerate}
\end{lem}

\begin{pof}
(i) is immediate from Definition~\ref{m_rooted} and the observation that
$$Q^{-1}=I-E_{kn}=\begin{pmatrix}
1 &  & & &  & 0 \\
 & 1 &  &      &  &  \\
 &  & \ddots & &  & -1 \\
 &  &        & &  &  \\
  &  & & & 1 &  \\
0 &  & & &  & 1 \\
\end{pmatrix},$$
and $Q^{-1}C'Q$ is
$$\begin{pmatrix}
c'_{11}     & c'_{12} & \cdots     & c'_{1\ n-1} & c'_{1k}+c'_{1n} \\
\vdots \\
c'_{k-11}     & c'_{k-1 2}           & \cdots     & c'_{k-1 n-1} & c'_{k-1k}+c'_{k-1n} \\
c'_{k1}-c'_{n1} & c'_{k2}-c'_{n2} &\cdots      &c'_{kn-1}-c'_{nk-1}& c'_{kk}+c'_{kn}-c'_{nk}-x'_{nn}\\
c'_{k+11}     & c'_{k+12}           & \cdots     & c'_{k+1\ n-1} & c'_{k+1k}+c'_{k+1n} \\
\vdots              & \vdots & \ddots              & \vdots & \vdots \\
c'_{n1}             & c'_{n2} & \cdots             & c'_{n\ n-1} & c'_{nk}+c'_{nn} \\
\end{pmatrix}.
$$



(ii)
By Lemma~\ref{lem:rt_vec} $v'=Qu$ is $k$-rooted.
Since $Q^{-1}C'Qu=\rho(C')u$ by the assumption, we have
$Q^{-1} C' Q u  = Q^{-1} \rho(C') Qu  =\rho(C')u$  \\
$C'Qu=\rho(C')Qu$.



(iii)
Since $C'$ and $Q^{-1}C'Q$ have the same set of eigenvalues, clearly $\rho(C')$ = $\rho(Q^{-1}C'Q)$.

\end{pof}


\begin{lem}\label{l_diag}
If a square matrix $C'$ has a rooted eigenvector for $\lambda'$, then $C'+dI$ also has
the same rooted eigenvector for $\lambda'+d,$ where $d$ is a constant and $I$ is the identity matrix with the same size of $C'$.
\end{lem}

\begin{thm}
Let $C$ be an $n\times n$ nonnegative matrix. For $1\leq i \leq n$ and $1\leq j\leq n-1$, choose $c'_{ij}$
such that $c'_{ij}\geq c_{ij}$ and $c'_{kj}\geq c'_{nj}>0$, and choose $r'_i$ such that $r'_i\geq c_{ik}+c_{in}$, and
$r'_k \geq r'_n$. Moreover choose $c'_{in}:=r'_i-c'_{ik}$. Then $\rho(C)\leq \rho(C')$, when $C'=(c'_{ij})$.
\end{thm}

\begin{pof}
These assumptions are necessary that $PCQ \leq PC'Q$, and C' is $k$-rooted,based on
 (\ref{lma_m_rooted});\\
 calculation:  \\
    \\
 by \ref{l_diag}, For certain d, if $C'+dI$ is $k$-rooted, then it has
  a $k$-rooted eigenvector with its spectral radius $\lambda + d$. C' would share the same
   eigenvector with $C'+dI$ and has eigenvalue $\lambda$. So $C'+dI$ and $C+dI$ meet the
    conditions of \ref{thm_main}, and we can show that $\rho(C' + dI) \geq \rho(C +dI)$ and
     then $\rho(C') \geq \rho(C)$  \qed
\end{pof}



\section{Example}
For the following $4\times 4$ matrix
$$C=\begin{pmatrix}
0 & 0 & 1 & 1\\
1 & 0 & 0 & 1\\
1 & 1 & 0 & 1\\
1 & 1 & 1 & 0
\end{pmatrix},$$
we choose
$$C'=\begin{pmatrix}
0 & 0 & 1 & 1\\
1 & 0 & 1 &  0\\
1 & 1 & 0 & 1\\
1 & 1 & 1 & 0
\end{pmatrix}.$$
Check the conditions of theorem~\ref{thm_main},   
Then
$\rho(C)\leq \rho(C')$ by Theorem 4.8. % @@@@@@@@@@@




\section{Counterexample}
For the following two $4\times 4$ matrices
$$C=\begin{pmatrix}
0 & 0 & 1 & 1\\
1 & 0 & 0 & 1\\
1 & 1 & 0 & 0\\
1 & 1 & 1 & 0
\end{pmatrix},\quad C'=\begin{pmatrix}
0 & 0 & 1 & 1\\
1 & 0 & 1 &  0\\
1 & 1 & 0 & 0\\
1 & 1 & 1 & 0
\end{pmatrix},$$
specify $n$=4, $k$=3 in $Q = I +E_{kn} = I + E_{34}$  
$$CQ=\begin{pmatrix}
0 & 0 & 1 & 2\\
1 & 0 & 0 & 1\\
1 & 1 & 0 & 0\\
1 & 1 & 1 & 1
\end{pmatrix},\quad C'Q=\begin{pmatrix}
0 & 0 & 1 & 2\\
1 & 0 & 1 & 1\\
1 & 1 & 0 & 0\\
1 & 1 & 1 & 1
\end{pmatrix},$$

we have $CQ\leq C'Q$, but
$\rho(C)=2.234\not\leq 2.148= \rho(C')$.
This is because $c'_{33}+c'_{34}\not\geq c'_{43}+c'_{44}$.



\end{document}